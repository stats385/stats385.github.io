---
layout: default
---

## Some Useful Links

<strong>Workshops</strong>  
<ol>
    <li>
    <a href="https://deepmath-conference.com"> Conference on the Mathematical Theory of Deep Neural Networks, NYU, Oct 31--Nov 1, 2019
 </a> <br>
   While deep learning has achieved impressive empirical success, the dearth of rigorous analysis limits their usefulness in addressing scientific questions and, more broadly, hinders systematic design of the next generation of networks. Recently, long-past-due theoretical results have begun to emerge from researchers in a number of fields. The purpose of this conference is to give visibility to these results and to shed light on the properties of large, adaptive, distributed learning architectures. 
    </li>
     <li>
    <a href="https://www.nature.com/articles/nature14539"> New In ML 2019: The First Group Session for Newcomers to Machine Learning
  </a><br>
  This is an official new experiment of NeurIPS to coach students to get papers accepted at NeurIPS. Papers accepted at this workshop will be reviewed by expert NeurIPS reviewers and, if accepted, will get a talk or a poster at the workshop and expect coaching. This will NOT count as an official publication, so papers submitted can then be revised and submitted to NeurIPS 2020!
    </li>

</ol>

<strong>Blogs</strong>  
<ol>
- [Open AI](https://blog.openai.com/)
- [Distill](https://distill.pub/)
- [BAIR Blog](http://bair.berkeley.edu/blog/)
- [DeepMind Blog](https://deepmind.com/blog/?category=research)
- [Andrej Karpathy’s Blog](http://karpathy.github.io/)
- [Colah’s Blog](http://colah.github.io/)
- [WildML](http://www.wildml.com/)
- [Ruder’s Blog](http://ruder.io/)
- [FAIR Blog](https://research.fb.com/blog/)
- [inFERENCe](http://www.inference.vc/)
- [Andrew Trask’s Blog](http://iamtrask.github.io/)
- [Graduate Descent](http://timvieira.github.io/blog/)
- [Adit Deshpande’s Blog](https://adeshpande3.github.io/)

</ol>

[back](./)
